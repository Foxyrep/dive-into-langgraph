{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 向量库知识智能体 (DB Agent RAG)\n",
    "\n",
    "---\n",
    "\n",
    "本教程演示如何将 `files` 目录下的 txt 文件按空行分段，写入 Chroma 内存向量库，并通过 ReAct Agent 检索回答。\n",
    "\n",
    "### 数据准备提示\n",
    "1. 请在当前目录下创建一个 `files` 文件夹。\n",
    "2. 在其中放入 `.txt` 文件。\n",
    "3. **注意**：若是 Excel 数据，需额外写脚本将列表头转为以下格式（空行分割），问答效果更准：\n",
    "\n",
    "```text\n",
    "问题：<问题内容>\n",
    "答案：<答案内容>\n",
    "\n",
    "（此处为空行）\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入依赖与加载环境\n",
    "\n",
    "确保目录下存在 `.env` 文件，包含 `DASHSCOPE_API_KEY` 和 `DASHSCOPE_BASE_URL`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_chroma import Chroma\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "\n",
    "# 加载模型配置\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 配置大模型与客户端"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置大模型 (LangChain)\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    "    model=\"qwen3-coder-plus\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# 创建 OpenAI 客户端 (用于 Embeddings)\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    base_url=os.getenv(\"DASHSCOPE_BASE_URL\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 定义 DashScope Embeddings\n",
    "\n",
    "自定义 Embeddings 类以适配 LangChain 接口。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DashScopeEmbeddings(Embeddings):\n",
    "    \"\"\"DashScope 兼容的 Embeddings 封装。\"\"\"\n",
    "\n",
    "    def __init__(self, model: str = \"text-embedding-v4\", dimensions: int = 1024):\n",
    "        self.model = model\n",
    "        self.dimensions = dimensions\n",
    "\n",
    "    def embed_documents(self, texts: list[str]) -> list[list[float]]:\n",
    "        vectors: list[list[float]] = []\n",
    "        for i in range(0, len(texts), 10):\n",
    "            chunk = texts[i : i + 10]\n",
    "            response = client.embeddings.create(\n",
    "                model=self.model,\n",
    "                input=chunk,\n",
    "                dimensions=self.dimensions,\n",
    "            )\n",
    "            vectors.extend([item.embedding for item in response.data])\n",
    "        return vectors\n",
    "\n",
    "    def embed_query(self, text: str) -> list[float]:\n",
    "        response = client.embeddings.create(\n",
    "            model=self.model,\n",
    "            input=[text],\n",
    "            dimensions=self.dimensions,\n",
    "        )\n",
    "        return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 文档加载逻辑\n",
    "\n",
    "读取目录下的 txt 文件，并使用**空行**进行切分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt_documents(data_dir: Path) -> list[Document]:\n",
    "    \"\"\"读取目录下的 txt 文件并按空行分割为 Document。\"\"\"\n",
    "\n",
    "    def split_on_blank(text: str) -> Iterable[str]:\n",
    "        for block in re.split(r\"\\n\\s*\\n\", text):\n",
    "            cleaned = block.strip()\n",
    "            if cleaned:\n",
    "                yield cleaned\n",
    "\n",
    "    documents: list[Document] = []\n",
    "    # 检查目录是否存在\n",
    "    if not data_dir.exists():\n",
    "        print(f\"Warning: 目录 {data_dir} 不存在\")\n",
    "        return []\n",
    "\n",
    "    for path in sorted(data_dir.glob(\"*.txt\")):\n",
    "        content = path.read_text(encoding=\"utf-8\")\n",
    "        for idx, part in enumerate(split_on_blank(content)):\n",
    "            documents.append(\n",
    "                Document(\n",
    "                    page_content=part,\n",
    "                    metadata={\"source\": path.name, \"chunk_id\": idx},\n",
    "                )\n",
    "            )\n",
    "    if not documents:\n",
    "        print(f\"目录 {data_dir} 下未找到 txt 文档\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 构建向量数据库\n",
    "\n",
    "连接到 Chroma 服务并写入数据。\n",
    "\n",
    "> **注意**：此处配置连接到远程 Chroma 服务器 (`120.24.168.78:7020`)。如果需要本地运行，请注释掉 `client_settings` 参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vector_store(data_dir: Path | None = None) -> Chroma:\n",
    "    \"\"\"读取 txt 文件并构建内存向量库。\"\"\"\n",
    "    # 在 Notebook 中，默认指向当前目录下的 files\n",
    "    target_dir = data_dir or (Path.cwd() / \"files\")\n",
    "    documents = load_txt_documents(target_dir)\n",
    "\n",
    "    print(f\"成功加载 {len(documents)} 个文档到向量库\")\n",
    "\n",
    "    embeddings = DashScopeEmbeddings()\n",
    "    \n",
    "    # 配置 Chroma 设置\n",
    "    chroma_settings = Settings(\n",
    "        chroma_server_host=\"120.24.168.78\",\n",
    "        chroma_server_http_port=7020\n",
    "    )\n",
    "    \n",
    "    vector_store = Chroma(\n",
    "        collection_name=\"test_collection\",\n",
    "        embedding_function=embeddings,\n",
    "        persist_directory=None,\n",
    "        client_settings=chroma_settings\n",
    "    )\n",
    "    \n",
    "    # 清空集合（可选，防止重复数据堆积）\n",
    "    try:\n",
    "        existing_ids = vector_store.get()[\"ids\"]\n",
    "        if existing_ids:\n",
    "            vector_store.delete(ids=existing_ids)\n",
    "    except Exception as e:\n",
    "        print(f\"连接或清理数据库时提示: {e}\")\n",
    "    \n",
    "    # 添加文档\n",
    "    if documents:\n",
    "        _ = vector_store.add_documents(documents)\n",
    "    \n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 创建 ReAct Agent\n",
    "\n",
    "定义检索工具并初始化 Agent。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_react_agent_wrapper(vector_store: Chroma):\n",
    "    \"\"\"基于给定向量库创建带检索工具的 ReAct Agent。\"\"\"\n",
    "\n",
    "    @tool(response_format=\"content_and_artifact\")\n",
    "    def retrieve_context(query: str):\n",
    "        \"\"\"基于向量库检索与问题最相关的文本片段。\"\"\"\n",
    "        retrieved = vector_store.similarity_search(query, k=3)\n",
    "        serialized = \"\\n\\n\".join(\n",
    "            f\"[{doc.metadata['source']}#{doc.metadata['chunk_id']}] {doc.page_content}\"\n",
    "            for doc in retrieved\n",
    "        )\n",
    "        return serialized, retrieved\n",
    "\n",
    "    return create_agent(\n",
    "        llm,\n",
    "        tools=[retrieve_context],\n",
    "        system_prompt=(\n",
    "            \"你可以使用检索工具获得参考资料。回答时结合检索到的内容，\"\n",
    "            \"如有必要可以在答案中简单引用来源标识。\"\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 运行演示\n",
    "\n",
    "执行以下代码块开始提问。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载 8 个文档到向量库\n",
      "嵌入完成\n",
      "\n",
      "Query: 公司的考勤方式是什么？\n",
      "--------------------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "公司的考勤方式是什么？\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "为了找到公司的考勤方式，我将采取以下步骤进行搜索：\n",
      "\n",
      "1. 首先确定公司是否有明确的考勤制度及相关规定。\n",
      "2. 然后查找具体的考勤方式，例如打卡、签到等。\n",
      "\n",
      "现在我开始第一步，通过检索来确定公司的考勤制度和相关规定。\n",
      "Tool Calls:\n",
      "  retrieve_context (call_9f3fed5b0751468f8a2ffd1f)\n",
      " Call ID: call_9f3fed5b0751468f8a2ffd1f\n",
      "  Args:\n",
      "    query: 公司的考勤制度和相关规定\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "[question.txt#0] 问题:公司的考勤方式是什么？\n",
      "答案:公司实行弹性打卡。\n",
      "权限: IT组、运维组\n",
      "关键词:考勤方式\n",
      "\n",
      "[question.txt#1] 问题:公司的考勤方式是什么？\n",
      "答案:公司实行固定世界打卡。\n",
      "权限: 运营组\n",
      "关键词:考勤方式\n",
      "\n",
      "[question.txt#5] 问题:休息不固定的人员考勤打卡有什么要求？\n",
      "答案:休息不固定的人员在当月休息天数在正常规定休息天数范围内，不需提交调休或请假申请，上班照常打2次卡（上/下班各一次）。\n",
      "权限:\n",
      "关键词:弹性休息、考勤打卡要求\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "公司的考勤方式是弹性打卡。\n"
     ]
    }
   ],
   "source": [
    "# 1. 准备并构建向量库\n",
    "vector_store = build_vector_store()\n",
    "print('嵌入完成' + '\\n')\n",
    "\n",
    "# 2. 创建 Agent\n",
    "agent = create_react_agent_wrapper(vector_store)\n",
    "\n",
    "# 3. 提问\n",
    "query = \"公司的考勤方式是什么？\"\n",
    "print(f\"Query: {query}\\n\" + \"-\" * 20)\n",
    "\n",
    "input_payload = {\"messages\": [{\"role\": \"user\", \"content\": query}]}\n",
    "\n",
    "for event in agent.stream(input_payload, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
